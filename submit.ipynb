{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "info = pd.read_csv(\n",
    "    \"node_information.csv\", \n",
    "    header= None, \n",
    "    names=[\"Id\", \"year\", \"title\", \"authors\", \"journal\", \"abstract\"],\n",
    "    sep=\",\",\n",
    "    index_col = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27770, 5) (615512, 2) (32648, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"training_set.txt\", sep=\" \", header=None)\n",
    "X_test = pd.read_csv(\"testing_set.txt\", sep=\" \", header=None)\n",
    "y_train = X_train[2]\n",
    "X_train.drop([2], axis = 1, inplace = True)\n",
    "\n",
    "print info.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################\n",
    "### FOR VALIDATION ###\n",
    "######################\n",
    "\n",
    "\n",
    "#####################\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "#####################\n",
    "\n",
    "#####################\n",
    "small_portion_to_train = 50000\n",
    "small_portion_to_test  = 5000\n",
    "#X_train = X_train[:small_portion_to_train]\n",
    "#y_train = y_train[:small_portion_to_train]\n",
    "\n",
    "#X_test  = X_test[:small_portion_to_test]\n",
    "#y_test = y_test[:small_portion_to_test]\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- list_authors is the list of authors in the papers\n",
    "- list_universities is the list where the authors are from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def universities_to_keep(authors, universities):\n",
    "    while('(' in authors and ')' in authors):\n",
    "        universities.append( authors[authors.find('(')+1 : authors.find(')')] )\n",
    "        authors = authors[: authors.find('(')] + authors[ authors.find(')')+1 : ]\n",
    "            \n",
    "    if '(' in authors:\n",
    "        universities.append( authors[authors.find('(')+1 : ])\n",
    "        authors = authors[: authors.find('(')]\n",
    "    \n",
    "    return authors, universities\n",
    "\n",
    "\n",
    "def name_to_keep(author):\n",
    "    if len(author.split(' ')) <= 1:\n",
    "        return author\n",
    "    \n",
    "    while( author[0] == ' ' and len(author) > 0):\n",
    "        author = author[1:]\n",
    "    while( author[-1] == ' ' and len(author) > 0):\n",
    "        author = author[:-1]\n",
    "    \n",
    "    author = author.replace('.', '. ')\n",
    "    author = author.replace('.  ', '. ')\n",
    "    name_to_keep = author.split(' ')[0][0] + '. ' + author.split(' ')[-1]\n",
    "\n",
    "    return name_to_keep\n",
    "\n",
    "# Transform concatenated names of authors to a list of authors \n",
    "list_authors = []\n",
    "list_universities = []\n",
    "\n",
    "info['authors'] = info['authors'].replace(np.nan, 'missing')\n",
    "for authors in info['authors']:\n",
    "    if authors != 'missing':\n",
    "        ### split the different authors\n",
    "        authors = authors.lower()\n",
    "        \n",
    "        ### Find the universities included in the name\n",
    "        universities = []\n",
    "        authors, universities = universities_to_keep(authors, universities)\n",
    "        \n",
    "        ### Split the authors\n",
    "        authors = re.split(',|&', authors)\n",
    "        \n",
    "        ### For each author, check if university, and store it. Also, keep just the names (To be improved)\n",
    "        authors_in_article = []      \n",
    "        for author in authors:\n",
    "            if author != ' ':\n",
    "                authors_in_article.append(name_to_keep(author))\n",
    "            \n",
    "        list_universities.append(universities)\n",
    "        list_authors.append(authors_in_article)\n",
    "    else:\n",
    "        list_universities.append(['missing'])\n",
    "        list_authors.append(['missing'])   \n",
    "        \n",
    "info['authors'] = list_authors\n",
    "info['universities'] = list_universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topologic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_graph(X_train, y_train, X_test):\n",
    "    X_train = pd.concat([X_train, y_train], axis = 1)\n",
    "    X_train = X_train.values\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(X_train.shape[0]):\n",
    "        source = X_train[i,0]\n",
    "        target = X_train[i,1]\n",
    "        G.add_node(source)\n",
    "        G.add_node(target)\n",
    "        if X_train[i,2] == 1:\n",
    "            G.add_edge(source,target)\n",
    "            \n",
    "    X_test = X_test.values\n",
    "    for i in range(X_test.shape[0]):\n",
    "        source = X_test[i,0]\n",
    "        target = X_test[i,1]\n",
    "        G.add_node(source)\n",
    "        G.add_node(target)\n",
    "        \n",
    "    return G  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = make_graph(X_train, y_train, X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 804 ms, total: 1min 26s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from create_topologic_features import create_topologic_features\n",
    "X_train = create_topologic_features(X_train, G)\n",
    "X_test = create_topologic_features(X_test, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Semantic features\n",
    "- Cosine similarity within the titles as tf-idf\n",
    "- Cosine similarity within the abstracts as tf-idf\n",
    "- Cosine similarity within the titles as word2vec\n",
    "- Cosine similarity within the abstracts as word2vec\n",
    "\n",
    "### To try\n",
    "- Difference cosine similarities?\n",
    "- Keep the stopwords or not?\n",
    "- Stemmise the words of not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Parsing sentences from training set"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "/home/bat/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:146: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken for K Means clustering:  59.4925282001 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def text_to_wordlist(text, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    text = re.sub(\"[\\W]\",\" \", text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)\n",
    "\n",
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "nltk.download(\"punkt\")   \n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def text_to_sentences(text, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a text into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(text.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append(text_to_wordlist(raw_sentence, remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences\n",
    "\n",
    "train = False\n",
    "sentences = []  # Initialize an empty list of sentences\n",
    "word_list_abstract=pd.Series(index=info.index,dtype=np.str)\n",
    "word_list_title=pd.Series(index=info.index,dtype=np.str)\n",
    "print \"Parsing sentences from training set\"\n",
    "for idx in info.index:\n",
    "    w_list_a = text_to_sentences(info.loc[idx,\"abstract\"], tokenizer, True)\n",
    "    sentences += w_list_a\n",
    "    word_list_abstract[idx]= w_list_a\n",
    "    w_list_t = text_to_sentences(info.loc[idx,\"title\"], tokenizer, True)\n",
    "    sentences += w_list_t\n",
    "    word_list_title[idx]= w_list_t\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "num_features = 200    # Word vector dimensionality  \n",
    "if train:\n",
    "    # Import the built-in logging module and configure it so that Word2Vec \n",
    "    # creates nice output messages\n",
    "    import logging\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "    # Set values for various parameters\n",
    "                    \n",
    "    min_word_count = 10   # Minimum word count                        \n",
    "    num_workers = 4       # Number of threads to run in parallel\n",
    "    context = 10          # Context window size                                                                                    \n",
    "    downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "    # Initialize and train the model (this will take some time)\n",
    "\n",
    "    print \"Training model...\"\n",
    "    model = word2vec.Word2Vec(\n",
    "        sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling\n",
    "    )\n",
    "\n",
    "    # If you don't plan to train the model any further, calling \n",
    "    # init_sims will make the model much more memory-efficient.\n",
    "    model.init_sims(replace=True)\n",
    "\n",
    "    # It can be helpful to create a meaningful model name and \n",
    "    # save the model for later use. You can load it later using Word2Vec.load()\n",
    "    model_name = \"200features_10minwords_10context\"\n",
    "    model.save(model_name)\n",
    "else:\n",
    "    model = Word2Vec.load(\"200features_10minwords_10context\")\n",
    "\n",
    "def makeFeatureVec(list_of_words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in list_of_words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(text_list, model, num_features):\n",
    "    # Given a set of texts (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0.\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    textFeatureVecs = np.zeros((len(text_list),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for list_of_words in text_list:\n",
    "        # Print a status message every 1000th review\n",
    "        \"\"\"\n",
    "        if counter%1000. == 0.:\n",
    "            print \"Review %d of %d\" % (counter, len(text_list))\n",
    "        \"\"\"\n",
    "        # Call the function (defined above) that makes average feature vectors\n",
    "        textFeatureVecs[counter] = makeFeatureVec(list_of_words, model, num_features)\n",
    "\n",
    "        # Increment the counter\n",
    "        counter = counter + 1.\n",
    "    return textFeatureVecs\n",
    "\n",
    "centroid_title = dict(zip(info.index, getAvgFeatureVecs(info.title.values, model, num_features)))\n",
    "centroid_abstract = dict(zip(info.index, getAvgFeatureVecs(info.abstract.values, model, num_features)))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\"\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n",
    "\n",
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids\n",
    "\n",
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "bag_centroids_abstract = {}\n",
    "#centroids_title = {}\n",
    "# Transform the training set reviews into bags of centroids\n",
    "for review, idx in zip(word_list_abstract, word_list_abstract.index):\n",
    "    bag_centroids_abstract[idx] = create_bag_of_centroids(review[0], word_centroid_map)\n",
    "#for review, idx in zip(word_list_title, word_list_title.index):\n",
    "#    centroids_title[idx] = create_bag_of_centroids( review[0], word_centroid_map )\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "def compute_cosines(centroids_dic, X):\n",
    "    bag=[cosine(centroids_dic[x[0]], centroids_dic[x[1]]) for x in X]\n",
    "    return np.array(bag)\n",
    "\n",
    "def create_nlp_features(X, centroid_title, centroid_abstract, bag_centroids_abstract):\n",
    "    X_ = X.copy()\n",
    "    X = X.values\n",
    "    \n",
    "    X_['CosineD_title_centroid'] = compute_cosines(centroid_title,X)\n",
    "    X_['CosineD_abstract_centroid'] = compute_cosines(centroid_abstract,X)\n",
    "    X_['CosineD_abstract_bag_centroids'] = compute_cosines(bag_centroids_abstract,X)\n",
    "    \n",
    "    return X_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 78.1 ms, total: 1min 18s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = create_nlp_features(X_train, centroid_title, centroid_abstract, bag_centroids_abstract)\n",
    "X_test = create_nlp_features(X_test,centroid_title, centroid_abstract, bag_centroids_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Attribute features\n",
    "\n",
    "- Difference in publication year\n",
    "- Number of common authors\n",
    "- Self-citation\n",
    "- Same journal\n",
    "- Number of times \"to\" cited (Attraction of the \"to\" paper)\n",
    "\n",
    "### To try\n",
    "- Number of times each author of \"to\" cited [Sum of these number of times] ?\n",
    "- Number of times each journal cited?\n",
    "- Number of same university??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 45s, sys: 1.49 s, total: 3min 47s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from create_attribute_features import create_attribute_features\n",
    "X_train = create_attribute_features(X_train,info)\n",
    "X_test = create_attribute_features(X_test,info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Graph Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 4s, sys: 2.34 s, total: 8min 7s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from author_graph import make_graph_authors, create_topologic_features_authors\n",
    "\n",
    "G_authors = make_graph_authors(X_train, y_train, info)\n",
    "X_train = create_topologic_features_authors(X_train, G_authors, info, betweeness = True, common_neigh_and_jacc = True, inlinks = True)\n",
    "X_test = create_topologic_features_authors(X_test, G_authors, info,  betweeness = True, common_neigh_and_jacc = True, inlinks = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Betweeness centrality</th>\n",
       "      <th>Number common neighbours</th>\n",
       "      <th>Jaccard coefficienf</th>\n",
       "      <th>Difference in inlinks coefficient</th>\n",
       "      <th>Number of times to cited</th>\n",
       "      <th>Same cluster</th>\n",
       "      <th>CosineD_title_centroid</th>\n",
       "      <th>CosineD_abstract_centroid</th>\n",
       "      <th>...</th>\n",
       "      <th>Self citation</th>\n",
       "      <th>Same journal</th>\n",
       "      <th>Authors betweeness</th>\n",
       "      <th>Authors common neighbors</th>\n",
       "      <th>Authors jaccard</th>\n",
       "      <th>Authors max difference in inlinks</th>\n",
       "      <th>Authors sum difference in inlinks</th>\n",
       "      <th>Authors max of times to cited</th>\n",
       "      <th>Authors sum of times to cited</th>\n",
       "      <th>Authors  of times to cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.080947</td>\n",
       "      <td>636</td>\n",
       "      <td>0.097952</td>\n",
       "      <td>-5247</td>\n",
       "      <td>-4982</td>\n",
       "      <td>426</td>\n",
       "      <td>161</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9707075</td>\n",
       "      <td>9604178</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>20</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>113</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026033</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063470</td>\n",
       "      <td>413</td>\n",
       "      <td>0.324430</td>\n",
       "      <td>363</td>\n",
       "      <td>682</td>\n",
       "      <td>1086</td>\n",
       "      <td>758</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9312155</td>\n",
       "      <td>9506142</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009869</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9911255</td>\n",
       "      <td>302165</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.056456</td>\n",
       "      <td>291</td>\n",
       "      <td>0.266728</td>\n",
       "      <td>222</td>\n",
       "      <td>214</td>\n",
       "      <td>667</td>\n",
       "      <td>667</td>\n",
       "      <td>667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9701033</td>\n",
       "      <td>209076</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.116592</td>\n",
       "      <td>134</td>\n",
       "      <td>0.020685</td>\n",
       "      <td>-5393</td>\n",
       "      <td>-5389</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1  Betweeness centrality  Number common neighbours  \\\n",
       "0  9510123  9502114              -0.000216                         1   \n",
       "1  9707075  9604178              -0.002449                        20   \n",
       "2  9312155  9506142              -0.000144                         0   \n",
       "3  9911255   302165               0.000216                         0   \n",
       "4  9701033   209076              -0.000612                         0   \n",
       "\n",
       "   Jaccard coefficienf  Difference in inlinks coefficient  \\\n",
       "0             0.058824                                  5   \n",
       "1             0.097087                                113   \n",
       "2             0.000000                                  1   \n",
       "3             0.000000                                 -2   \n",
       "4             0.000000                                 -5   \n",
       "\n",
       "   Number of times to cited  Same cluster  CosineD_title_centroid  \\\n",
       "0                         8             0                0.003766   \n",
       "1                       124             1                0.026033   \n",
       "2                         2             0                0.009869   \n",
       "3                         2             1                0.004979   \n",
       "4                         2             0                0.005345   \n",
       "\n",
       "   CosineD_abstract_centroid             ...              Self citation  \\\n",
       "0                   0.001423             ...                          0   \n",
       "1                   0.001301             ...                          0   \n",
       "2                   0.001369             ...                          0   \n",
       "3                   0.000687             ...                          0   \n",
       "4                   0.000681             ...                          0   \n",
       "\n",
       "   Same journal  Authors betweeness  Authors common neighbors  \\\n",
       "0             1            1.080947                       636   \n",
       "1             0           -0.063470                       413   \n",
       "2             0           -0.005749                         1   \n",
       "3             0           -0.056456                       291   \n",
       "4             0            1.116592                       134   \n",
       "\n",
       "   Authors jaccard  Authors max difference in inlinks  \\\n",
       "0         0.097952                              -5247   \n",
       "1         0.324430                                363   \n",
       "2         0.023256                                 14   \n",
       "3         0.266728                                222   \n",
       "4         0.020685                              -5393   \n",
       "\n",
       "   Authors sum difference in inlinks  Authors max of times to cited  \\\n",
       "0                              -4982                            426   \n",
       "1                                682                           1086   \n",
       "2                                 13                             15   \n",
       "3                                214                            667   \n",
       "4                              -5389                             19   \n",
       "\n",
       "   Authors sum of times to cited  Authors  of times to cited  \n",
       "0                            161                       154.0  \n",
       "1                            758                       543.0  \n",
       "2                             15                        15.0  \n",
       "3                            667                       667.0  \n",
       "4                             15                         9.5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>Betweeness centrality</th>\n",
       "      <th>Number common neighbours</th>\n",
       "      <th>Jaccard coefficienf</th>\n",
       "      <th>Difference in inlinks coefficient</th>\n",
       "      <th>Number of times to cited</th>\n",
       "      <th>Same cluster</th>\n",
       "      <th>CosineD_title_centroid</th>\n",
       "      <th>CosineD_abstract_centroid</th>\n",
       "      <th>...</th>\n",
       "      <th>Self citation</th>\n",
       "      <th>Same journal</th>\n",
       "      <th>Authors betweeness</th>\n",
       "      <th>Authors common neighbors</th>\n",
       "      <th>Authors jaccard</th>\n",
       "      <th>Authors max difference in inlinks</th>\n",
       "      <th>Authors sum difference in inlinks</th>\n",
       "      <th>Authors max of times to cited</th>\n",
       "      <th>Authors sum of times to cited</th>\n",
       "      <th>Authors  of times to cited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9807076</td>\n",
       "      <td>9807139</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-46</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>424</td>\n",
       "      <td>0.275325</td>\n",
       "      <td>-383</td>\n",
       "      <td>-1352</td>\n",
       "      <td>678</td>\n",
       "      <td>539</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109162</td>\n",
       "      <td>1182</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>24</td>\n",
       "      <td>0.074303</td>\n",
       "      <td>-61</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.082327</td>\n",
       "      <td>302</td>\n",
       "      <td>0.258120</td>\n",
       "      <td>-145</td>\n",
       "      <td>277</td>\n",
       "      <td>719</td>\n",
       "      <td>297</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9702187</td>\n",
       "      <td>9510135</td>\n",
       "      <td>-0.018582</td>\n",
       "      <td>59</td>\n",
       "      <td>0.065338</td>\n",
       "      <td>517</td>\n",
       "      <td>726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.819018</td>\n",
       "      <td>2465</td>\n",
       "      <td>0.374677</td>\n",
       "      <td>3183</td>\n",
       "      <td>2003</td>\n",
       "      <td>5408</td>\n",
       "      <td>5408</td>\n",
       "      <td>5408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111048</td>\n",
       "      <td>110115</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>21</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.070829</td>\n",
       "      <td>358</td>\n",
       "      <td>0.229487</td>\n",
       "      <td>577</td>\n",
       "      <td>1275</td>\n",
       "      <td>1680</td>\n",
       "      <td>872</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9910176</td>\n",
       "      <td>9410073</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.143498</td>\n",
       "      <td>289</td>\n",
       "      <td>0.135681</td>\n",
       "      <td>1108</td>\n",
       "      <td>3146</td>\n",
       "      <td>3367</td>\n",
       "      <td>1329</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1  Betweeness centrality  Number common neighbours  \\\n",
       "0  9807076  9807139               0.001476                         0   \n",
       "1   109162     1182               0.009291                        24   \n",
       "2  9702187  9510135              -0.018582                        59   \n",
       "3   111048   110115              -0.000504                        21   \n",
       "4  9910176  9410073              -0.005150                         0   \n",
       "\n",
       "   Jaccard coefficienf  Difference in inlinks coefficient  \\\n",
       "0             0.000000                                -46   \n",
       "1             0.074303                                -61   \n",
       "2             0.065338                                517   \n",
       "3             0.221053                                  5   \n",
       "4             0.000000                                143   \n",
       "\n",
       "   Number of times to cited  Same cluster  CosineD_title_centroid  \\\n",
       "0                         3             1                0.011031   \n",
       "1                        39             1                0.003334   \n",
       "2                       726             1                0.008947   \n",
       "3                        16             1                0.009270   \n",
       "4                       144             1                0.001355   \n",
       "\n",
       "   CosineD_abstract_centroid             ...              Self citation  \\\n",
       "0                   0.001181             ...                          0   \n",
       "1                   0.001054             ...                          0   \n",
       "2                   0.001919             ...                          0   \n",
       "3                   0.000746             ...                          0   \n",
       "4                   0.001571             ...                          0   \n",
       "\n",
       "   Same journal  Authors betweeness  Authors common neighbors  \\\n",
       "0             0            0.069564                       424   \n",
       "1             0            0.082327                       302   \n",
       "2             1           -0.819018                      2465   \n",
       "3             1           -0.070829                       358   \n",
       "4             0           -0.143498                       289   \n",
       "\n",
       "   Authors jaccard  Authors max difference in inlinks  \\\n",
       "0         0.275325                               -383   \n",
       "1         0.258120                               -145   \n",
       "2         0.374677                               3183   \n",
       "3         0.229487                                577   \n",
       "4         0.135681                               1108   \n",
       "\n",
       "   Authors sum difference in inlinks  Authors max of times to cited  \\\n",
       "0                              -1352                            678   \n",
       "1                                277                            719   \n",
       "2                               2003                           5408   \n",
       "3                               1275                           1680   \n",
       "4                               3146                           3367   \n",
       "\n",
       "   Authors sum of times to cited  Authors  of times to cited  \n",
       "0                            539                         339  \n",
       "1                            297                         215  \n",
       "2                           5408                        5408  \n",
       "3                            872                         532  \n",
       "4                           1329                        1171  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(pred, real):\n",
    "    tot = 0\n",
    "    for i, val in enumerate(real):\n",
    "        if pred[i] == val:\n",
    "            tot += 1\n",
    "    return float(tot)/len(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(\"train_set/X_train.csv\")\n",
    "X_test.to_csv(\"train_set/X_test.csv\")\n",
    "y_train.to_csv(\"train_set/y_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run from here if the data are already created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "def score(pred, real):\n",
    "    tot = 0\n",
    "    for i, val in enumerate(real):\n",
    "        if pred[i] == val:\n",
    "            tot += 1\n",
    "    return float(tot)/len(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"train_set/\"\n",
    "\n",
    "X_train = pd.read_csv(path+\"X_train.csv\",index_col=0)\n",
    "X_test = pd.read_csv(path+\"X_test.csv\",index_col=0)\n",
    "y_train = pd.Series.from_csv(path+\"y_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_light = X_train.drop([\"Number common neighbours\",\"Self citation\",\"Same journal\",\"Authors betweeness\",\"Authors max difference in inlinks\",\"Number of times to cited\"], axis = 1)\n",
    "X_test_light = X_test.drop([\"Number common neighbours\",\"Self citation\",\"Same journal\",\"Authors betweeness\",\"Authors max difference in inlinks\",\"Number of times to cited\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_light = X_train.drop([\"Number of times to cited\"], axis = 1)\n",
    "X_test_light = X_test.drop([\"Number of times to cited\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_light2 = X_train.drop([\"Number common neighbours\",\"Self citation\",\"Same journal\",\"Authors max difference in inlinks\",\n",
    "                                   \"Number of times to cited\",\"Authors  of times to cited\"], axis = 1)\n",
    "X_test_light2 = X_test.drop([\"Number common neighbours\",\"Self citation\",\"Same journal\",\"Authors max difference in inlinks\",\n",
    "                             \"Number of times to cited\",\"Authors  of times to cited\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_light = X_train.drop([\"Number of times to cited\",\"Authors  of times to cited\"], axis = 1)\n",
    "X_test_light = X_test.drop([\"Number of times to cited\",\"Authors  of times to cited\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('neural network', Classifier(batch_size=100, callback=None, debug=True, dropout_rate=0.1,\n",
       "      f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Layer `Rectifier`: units=100, name=u'hidden0', frozen=False>,\n",
       "      hidden1=<sknn.nn.La...  [0, 1]])),\n",
       "      valid_size=0.1, verbose=1, warning=None, weight_decay=None,\n",
       "      weights=None))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sknn.mlp import Layer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sknn.mlp import Classifier as MLP\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "scaler1=StandardScaler()\n",
    "scaler = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "val_percent = 0.1\n",
    "nn = MLP(\n",
    "layers=[\n",
    "    Layer(\"Rectifier\", units=100),\n",
    "    Layer(\"Rectifier\", units=100),\n",
    "        Layer(\"Softmax\")],\n",
    "        learning_rule = 'momentum', learning_rate=0.04, batch_size = 100,dropout_rate =0.1,\n",
    "        n_iter=100,\n",
    "        verbose = 1, \n",
    "        valid_size = val_percent, \n",
    "        n_stable = 30,\n",
    "        debug = True,\n",
    "        #    regularize = 'L2'\n",
    "        random_state = 42\n",
    ")\n",
    "\n",
    "clfnn1 = Pipeline([\n",
    "    (\"scaler\", scaler1),\n",
    "    ('neural network', nn)\n",
    "    ])\n",
    "\n",
    "clfnn1.fit(X_train.values, y_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0.0, 1.0))), ('neural network', Classifier(batch_size=100, callback=None, debug=True, dropout_rate=0.1,\n",
       "      f_stable=0.001,\n",
       "      hidden0=<sknn.nn.Layer `Rectifier`: units=100, name=u'hidden0', frozen=False>,\n",
       "      hidden1=<sknn.nn.Layer `Re...  [0, 1]])),\n",
       "      valid_size=0.1, verbose=1, warning=None, weight_decay=None,\n",
       "      weights=None))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn2 = MLP(\n",
    "layers=[\n",
    "    Layer(\"Rectifier\", units=100),\n",
    "    Layer(\"Rectifier\", units=100),\n",
    "        Layer(\"Softmax\")],\n",
    "        learning_rule = 'momentum', learning_rate=0.05, batch_size = 100,dropout_rate =0.1,\n",
    "        n_iter=100,\n",
    "        verbose = 1, \n",
    "        valid_size = val_percent, \n",
    "        n_stable = 30,\n",
    "        debug = True,\n",
    "        random_state = 42\n",
    "        #    regularize = 'L2'\n",
    ")\n",
    "\n",
    "clfnn2 = Pipeline([\n",
    "    (\"scaler\", scaler),\n",
    "    ('neural network', nn2)\n",
    "    ])\n",
    "\n",
    "clfnn2.fit(X_train_light.values, y_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min, sys: 4.81 s, total: 18min 5s\n",
      "Wall time: 18min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators = 400)\n",
    "gbc.fit(X_train_light2, y_train)\n",
    "#pred = gbc.predict(X_test_light)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-e377b3c902a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'from sklearn.ensemble import ExtraTreesClassifier\\nclf = ExtraTreesClassifier(n_estimators = 600,n_jobs=1)\\nclf.fit(X_train_light2, y_train)\\npred = clf.predict(X_test_light2)\\nprint accuracy_score(pred, y_test)\\n#print score(clf.predict(X_train.drop([0,1], axis = 1)),y_train)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2291\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2293\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bat/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1167\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1168\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators = 600,n_jobs=1)\n",
    "clf.fit(X_train_light2, y_train)\n",
    "#pred = clf.predict(X_test_light2)\n",
    "#print accuracy_score(pred, y_test)\n",
    "#print score(clf.predict(X_train.drop([0,1], axis = 1)),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAIkCAYAAACN0sPaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXcHJy8VJ1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ab3f88690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "X_columns = X_train_light.columns\n",
    "ordering = np.argsort(gbc.feature_importances_)[::-1]\n",
    "\n",
    "importances = gbc.feature_importances_[ordering]\n",
    "feature_names = X_columns[ordering]\n",
    "\n",
    "x = np.arange(len(feature_names))\n",
    "plt.bar(x, importances)\n",
    "plt.xticks(x + 0.5, feature_names, rotation=90, fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSEMBLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_t = pd.read_csv(\"past_submits/submit7_97268.csv\").values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Betweeness centrality', u'Number common neighbours',\n",
       "       u'Jaccard coefficienf', u'Difference in inlinks coefficient',\n",
       "       u'Number of times to cited', u'Same cluster', u'CosineD_title_centroid',\n",
       "       u'CosineD_abstract_centroid', u'CosineD_abstract_bag_centroids',\n",
       "       u'Diff publication', u'Number same authors', u'Self citation',\n",
       "       u'Same journal', u'Authors betweeness', u'Authors common neighbors',\n",
       "       u'Authors jaccard', u'Authors max difference in inlinks',\n",
       "       u'Authors sum difference in inlinks', u'Authors max of times to cited',\n",
       "       u'Authors sum of times to cited', u'Authors  of times to cited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615512, 21)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_array = [gbc.predict_proba(X_test_light2)[:,1], \n",
    "                clfnn1.predict_proba(X_test)[:,1].flatten(),clfnn2.predict_proba(X_test_light)[:,1].flatten(),clf.predict_proba(X_test_light2)[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32648,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99568120558686601"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_t,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rounds(predict):\n",
    "    return [0 if pr<=0.5 else 1 for pr in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_pred(y_pred_array, weights = None):\n",
    "    if weights ==None:\n",
    "        weights = [1 for i in y_pred_array]\n",
    "    return np.array(rounds(1./sum(weights)*sum([weights[i]*y for i,y in enumerate(y_pred_array)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = make_pred(y_pred_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99568120558686601"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(rounds(y_pred_array[0]),pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(predicted_label, name = 'submit.csv'):\n",
    "    submit_d = d = {'id' : pd.Series(np.arange(predicted_label.shape[0]).astype(int)),\n",
    "                    'category' : pd.Series(predicted_label).astype(int)}\n",
    "    submit = pd.DataFrame(submit_d, columns=[\"id\",\"category\"])\n",
    "    submit.to_csv(name,index=False)\n",
    "    return submit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = make_submission(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32648, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[l for i,l in enumerate(pred)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
